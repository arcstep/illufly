{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# æ™ºè°±APIæµ‹è¯•"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ä½¿ç”¨ ChatZhipuAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydantic==1.10.13\n",
      "  Using cached pydantic-1.10.13-cp39-cp39-macosx_10_9_x86_64.whl.metadata (149 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/xuehongwei/Library/Caches/pypoetry/virtualenvs/langchain-chinese-gSQlHcwW-py3.9/lib/python3.9/site-packages (from pydantic==1.10.13) (4.10.0)\n",
      "Using cached pydantic-1.10.13-cp39-cp39-macosx_10_9_x86_64.whl (2.9 MB)\n",
      "Installing collected packages: pydantic\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.6.2\n",
      "    Uninstalling pydantic-2.6.2:\n",
      "      Successfully uninstalled pydantic-2.6.2\n",
      "Successfully installed pydantic-1.10.13\n"
     ]
    }
   ],
   "source": [
    "# !pip install pydantic==1.10.13\n",
    "# !pip install pydantic==2.6.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_zhipu import ChatZhipuAI\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import transformers python package. This is needed in order to calculate get_token_ids. Please install it with `pip install transformers`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain_core/language_models/base.py:40\u001b[0m, in \u001b[0;36mget_tokenizer\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GPT2TokenizerFast  \u001b[38;5;66;03m# type: ignore[import]\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m llm \u001b[38;5;241m=\u001b[39m ChatZhipuAI()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mabc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain_core/language_models/base.py:283\u001b[0m, in \u001b[0;36mBaseLanguageModel.get_num_tokens\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_num_tokens\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m    273\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get the number of tokens present in the text.\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m    Useful for checking if an input will fit in a model's context window.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;124;03m        The integer number of tokens in the text.\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_token_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain_core/language_models/base.py:270\u001b[0m, in \u001b[0;36mBaseLanguageModel.get_token_ids\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_token_ids\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mint\u001b[39m]:\n\u001b[1;32m    261\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the ordered ids of the tokens in a text.\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \n\u001b[1;32m    263\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;124;03m            in the text.\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 270\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_token_ids_default_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain_core/language_models/base.py:54\u001b[0m, in \u001b[0;36m_get_token_ids_default_method\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Encode the text into token IDs.\"\"\"\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# get the cached tokenizer\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mget_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# tokenize the text using the GPT-2 tokenizer\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mencode(text)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain_core/language_models/base.py:42\u001b[0m, in \u001b[0;36mget_tokenizer\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GPT2TokenizerFast  \u001b[38;5;66;03m# type: ignore[import]\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import transformers python package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     44\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is needed in order to calculate get_token_ids. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     45\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with `pip install transformers`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     46\u001b[0m     )\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# create a GPT-2 tokenizer instance\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m GPT2TokenizerFast\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: Could not import transformers python package. This is needed in order to calculate get_token_ids. Please install it with `pip install transformers`."
     ]
    }
   ],
   "source": [
    "llm = ChatZhipuAI()\n",
    "llm.get_num_tokens(text=\"abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import transformers python package. This is needed in order to calculate get_token_ids. Please install it with `pip install transformers`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain_core/language_models/base.py:40\u001b[0m, in \u001b[0;36mget_tokenizer\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GPT2TokenizerFast  \u001b[38;5;66;03m# type: ignore[import]\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_token_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhi\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain_core/language_models/base.py:270\u001b[0m, in \u001b[0;36mBaseLanguageModel.get_token_ids\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_token_ids\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mint\u001b[39m]:\n\u001b[1;32m    261\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the ordered ids of the tokens in a text.\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \n\u001b[1;32m    263\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;124;03m            in the text.\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 270\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_token_ids_default_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain_core/language_models/base.py:54\u001b[0m, in \u001b[0;36m_get_token_ids_default_method\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Encode the text into token IDs.\"\"\"\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# get the cached tokenizer\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mget_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# tokenize the text using the GPT-2 tokenizer\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mencode(text)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain_core/language_models/base.py:42\u001b[0m, in \u001b[0;36mget_tokenizer\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GPT2TokenizerFast  \u001b[38;5;66;03m# type: ignore[import]\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import transformers python package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     44\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is needed in order to calculate get_token_ids. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     45\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with `pip install transformers`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     46\u001b[0m     )\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# create a GPT-2 tokenizer instance\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m GPT2TokenizerFast\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: Could not import transformers python package. This is needed in order to calculate get_token_ids. Please install it with `pip install transformers`."
     ]
    }
   ],
   "source": [
    "llm.get_token_ids(text=\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ä½ å¥½ğŸ‘‹ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹æ™ºè°±æ¸…è¨€ï¼ˆChatGLMï¼‰ï¼Œå¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ä½ å¥½ğŸ‘‹ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹æ™ºè°±æ¸…è¨€ï¼ˆChatGLMï¼‰ï¼Œå¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await llm.ainvoke(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello| |ğŸ‘‹!| I|'|m| Chat|GL|M|ï¼ˆ|æ™º|è°±|æ¸…|è¨€|ï¼‰,| the| artificial| intelligence| assistant|,| nice| to| meet| you|.| Feel| free| to| ask| me| any| questions|.||"
     ]
    }
   ],
   "source": [
    "for chunk in llm.stream(\"hi\"):\n",
    "  print(chunk.content, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello|!| How| can| I| assist| you| today|?||"
     ]
    }
   ],
   "source": [
    "async for chunk in llm.astream(\"hi\"):\n",
    "  print(chunk.content, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'event': 'on_chat_model_start', 'run_id': '4f202b64-1034-455b-9bc4-5fc32e027565', 'name': 'ChatZhipuAI', 'tags': [], 'metadata': {}, 'data': {'input': 'hi'}}\n",
      "{'event': 'on_chat_model_stream', 'run_id': '4f202b64-1034-455b-9bc4-5fc32e027565', 'tags': [], 'metadata': {}, 'name': 'ChatZhipuAI', 'data': {'chunk': AIMessageChunk(content='ä½ å¥½')}}\n",
      "{'event': 'on_chat_model_stream', 'run_id': '4f202b64-1034-455b-9bc4-5fc32e027565', 'tags': [], 'metadata': {}, 'name': 'ChatZhipuAI', 'data': {'chunk': AIMessageChunk(content='ğŸ‘‹ï¼')}}\n",
      "{'event': 'on_chat_model_stream', 'run_id': '4f202b64-1034-455b-9bc4-5fc32e027565', 'tags': [], 'metadata': {}, 'name': 'ChatZhipuAI', 'data': {'chunk': AIMessageChunk(content='æˆ‘æ˜¯')}}\n",
      "{'event': 'on_chat_model_stream', 'run_id': '4f202b64-1034-455b-9bc4-5fc32e027565', 'tags': [], 'metadata': {}, 'name': 'ChatZhipuAI', 'data': {'chunk': AIMessageChunk(content='äººå·¥æ™ºèƒ½')}}\n",
      "{'event': 'on_chat_model_stream', 'run_id': '4f202b64-1034-455b-9bc4-5fc32e027565', 'tags': [], 'metadata': {}, 'name': 'ChatZhipuAI', 'data': {'chunk': AIMessageChunk(content='åŠ©æ‰‹')}}\n",
      "{'event': 'on_chat_model_stream', 'run_id': '4f202b64-1034-455b-9bc4-5fc32e027565', 'tags': [], 'metadata': {}, 'name': 'ChatZhipuAI', 'data': {'chunk': AIMessageChunk(content='æ™º')}}\n",
      "{'event': 'on_chat_model_stream', 'run_id': '4f202b64-1034-455b-9bc4-5fc32e027565', 'tags': [], 'metadata': {}, 'name': 'ChatZhipuAI', 'data': {'chunk': AIMessageChunk(content='è°±')}}\n",
      "{'event': 'on_chat_model_stream', 'run_id': '4f202b64-1034-455b-9bc4-5fc32e027565', 'tags': [], 'metadata': {}, 'name': 'ChatZhipuAI', 'data': {'chunk': AIMessageChunk(content='æ¸…')}}\n",
      "{'event': 'on_chat_model_stream', 'run_id': '4f202b64-1034-455b-9bc4-5fc32e027565', 'tags': [], 'metadata': {}, 'name': 'ChatZhipuAI', 'data': {'chunk': AIMessageChunk(content='è¨€')}}\n",
      "{'event': 'on_chat_model_stream', 'run_id': '4f202b64-1034-455b-9bc4-5fc32e027565', 'tags': [], 'metadata': {}, 'name': 'ChatZhipuAI', 'data': {'chunk': AIMessageChunk(content='ï¼ˆ')}}\n",
      "{'event': 'on_chat_model_stream', 'run_id': '4f202b64-1034-455b-9bc4-5fc32e027565', 'tags': [], 'metadata': {}, 'name': 'ChatZhipuAI', 'data': {'chunk': AIMessageChunk(content='C')}}\n",
      "{'event': 'on_chat_model_stream', 'run_id': '4f202b64-1034-455b-9bc4-5fc32e027565', 'tags': [], 'metadata': {}, 'name': 'ChatZhipuAI', 'data': {'chunk': AIMessageChunk(content='hat')}}\n",
      "{'event': 'on_chat_model_stream', 'run_id': '4f202b64-1034-455b-9bc4-5fc32e027565', 'tags': [], 'metadata': {}, 'name': 'ChatZhipuAI', 'data': {'chunk': AIMessageChunk(content='GL')}}\n",
      "{'event': 'on_chat_model_stream', 'run_id': '4f202b64-1034-455b-9bc4-5fc32e027565', 'tags': [], 'metadata': {}, 'name': 'ChatZhipuAI', 'data': {'chunk': AIMessageChunk(content='M')}}\n",
      "{'event': 'on_chat_model_stream', 'run_id': '4f202b64-1034-455b-9bc4-5fc32e027565', 'tags': [], 'metadata': {}, 'name': 'ChatZhipuAI', 'data': {'chunk': AIMessageChunk(content='ï¼‰ï¼Œ')}}\n",
      "{'event': 'on_chat_model_stream', 'run_id': '4f202b64-1034-455b-9bc4-5fc32e027565', 'tags': [], 'metadata': {}, 'name': 'ChatZhipuAI', 'data': {'chunk': AIMessageChunk(content='å¾ˆé«˜å…´')}}\n",
      "{'event': 'on_chat_model_stream', 'run_id': '4f202b64-1034-455b-9bc4-5fc32e027565', 'tags': [], 'metadata': {}, 'name': 'ChatZhipuAI', 'data': {'chunk': AIMessageChunk(content='è§åˆ°')}}\n",
      "{'event': 'on_chat_model_stream', 'run_id': '4f202b64-1034-455b-9bc4-5fc32e027565', 'tags': [], 'metadata': {}, 'name': 'ChatZhipuAI', 'data': {'chunk': AIMessageChunk(content='ä½ ')}}\n",
      "{'event': 'on_chat_model_stream', 'run_id': '4f202b64-1034-455b-9bc4-5fc32e027565', 'tags': [], 'metadata': {}, 'name': 'ChatZhipuAI', 'data': {'chunk': AIMessageChunk(content='ï¼Œ')}}\n",
      "{'event': 'on_chat_model_stream', 'run_id': '4f202b64-1034-455b-9bc4-5fc32e027565', 'tags': [], 'metadata': {}, 'name': 'ChatZhipuAI', 'data': {'chunk': AIMessageChunk(content='æ¬¢è¿')}}\n",
      "{'event': 'on_chat_model_stream', 'run_id': '4f202b64-1034-455b-9bc4-5fc32e027565', 'tags': [], 'metadata': {}, 'name': 'ChatZhipuAI', 'data': {'chunk': AIMessageChunk(content='é—®æˆ‘')}}\n",
      "{'event': 'on_chat_model_stream', 'run_id': '4f202b64-1034-455b-9bc4-5fc32e027565', 'tags': [], 'metadata': {}, 'name': 'ChatZhipuAI', 'data': {'chunk': AIMessageChunk(content='ä»»ä½•')}}\n",
      "{'event': 'on_chat_model_stream', 'run_id': '4f202b64-1034-455b-9bc4-5fc32e027565', 'tags': [], 'metadata': {}, 'name': 'ChatZhipuAI', 'data': {'chunk': AIMessageChunk(content='é—®é¢˜')}}\n",
      "{'event': 'on_chat_model_stream', 'run_id': '4f202b64-1034-455b-9bc4-5fc32e027565', 'tags': [], 'metadata': {}, 'name': 'ChatZhipuAI', 'data': {'chunk': AIMessageChunk(content='ã€‚')}}\n",
      "{'event': 'on_chat_model_stream', 'run_id': '4f202b64-1034-455b-9bc4-5fc32e027565', 'tags': [], 'metadata': {}, 'name': 'ChatZhipuAI', 'data': {'chunk': AIMessageChunk(content='')}}\n",
      "{'event': 'on_chat_model_end', 'name': 'ChatZhipuAI', 'run_id': '4f202b64-1034-455b-9bc4-5fc32e027565', 'tags': [], 'metadata': {}, 'data': {'output': AIMessageChunk(content='ä½ å¥½ğŸ‘‹ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹æ™ºè°±æ¸…è¨€ï¼ˆChatGLMï¼‰ï¼Œå¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚')}}\n"
     ]
    }
   ],
   "source": [
    "async for chunk in llm.astream_events(\"hi\", version=\"v1\"):\n",
    "  print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"query_train_info\",\n",
    "            \"description\": \"æ ¹æ®ç”¨æˆ·æä¾›çš„ä¿¡æ¯ï¼ŒæŸ¥è¯¢å¯¹åº”çš„è½¦æ¬¡\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"departure\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"å‡ºå‘åŸå¸‚æˆ–è½¦ç«™\",\n",
    "                    },\n",
    "                    \"destination\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"ç›®çš„åœ°åŸå¸‚æˆ–è½¦ç«™\",\n",
    "                    },\n",
    "                    \"date\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"è¦æŸ¥è¯¢çš„è½¦æ¬¡æ—¥æœŸ\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"departure\", \"destination\", \"date\"],\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatZhipuAI().bind(tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=ChatZhipuAI(client=<zhipuai._client.ZhipuAI object at 0x110ca1820>), kwargs={'tools': [{'type': 'function', 'function': {'name': 'query_train_info', 'description': 'æ ¹æ®ç”¨æˆ·æä¾›çš„ä¿¡æ¯ï¼ŒæŸ¥è¯¢å¯¹åº”çš„è½¦æ¬¡', 'parameters': {'type': 'object', 'properties': {'departure': {'type': 'string', 'description': 'å‡ºå‘åŸå¸‚æˆ–è½¦ç«™'}, 'destination': {'type': 'string', 'description': 'ç›®çš„åœ°åŸå¸‚æˆ–è½¦ç«™'}, 'date': {'type': 'string', 'description': 'è¦æŸ¥è¯¢çš„è½¦æ¬¡æ—¥æœŸ'}}, 'required': ['departure', 'destination', 'date']}}}]})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ä¸€åªç¾Šè¯´ï¼šâ€œæˆ‘æ¯å¤©éƒ½æ¯”ä¸€åªç‹¼è·‘å¾—å¿«ï¼Œå› ä¸ºæˆ‘æ¯”å®ƒæ›´ä¼šç»•åœˆå­ã€‚â€')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"ç»™æˆ‘è®²ä¸ªä¸€å¥è¯ç¬‘è¯\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_8415022186389879829', 'function': {'arguments': '{\"date\":\"2024-01-01\",\"departure\":\"åŒ—äº¬å—ç«™\",\"destination\":\"ä¸Šæµ·\"}', 'name': 'query_train_info'}, 'type': 'function'}]})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"ä½ èƒ½å¸®æˆ‘æŸ¥è¯¢2024å¹´1æœˆ1æ—¥ä»åŒ—äº¬å—ç«™åˆ°ä¸Šæµ·çš„ç«è½¦ç¥¨å—ï¼Ÿ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_8367745969533447732', 'function': {'arguments': '{\"date\":\"2024-01-01\",\"departure\":\"åŒ—äº¬å—ç«™\",\"destination\":\"ä¸Šæµ·\"}', 'name': 'query_train_info'}, 'type': 'function'}]}\n",
      "content=''\n"
     ]
    }
   ],
   "source": [
    "for chunk in llm.stream(\"ä½ èƒ½å¸®æˆ‘æŸ¥è¯¢2024å¹´1æœˆ1æ—¥ä»åŒ—äº¬å—ç«™åˆ°ä¸Šæµ·çš„ç«è½¦ç¥¨å—ï¼Ÿ\"):\n",
    "  print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='æ ¹æ®æä¾›çš„ä¿¡æ¯ï¼Œè´¾ç²çš„æœ€æ–°ä½œå“æ˜¯ã€Šçƒ­è¾£æ»šçƒ«ã€‹ï¼Œè¿™éƒ¨ç”µå½±åœ¨æ˜¥èŠ‚æ¡£æœŸä¸Šæ˜ ï¼Œå¹¶ä¸”å–å¾—äº†ç›¸å½“çš„æˆåŠŸï¼Œç¥¨æˆ¿è¶…è¿‡23.6äº¿å…ƒï¼Œè±†ç“£è¯„åˆ†è¾¾åˆ°äº†8.0åˆ†ï¼Œæ˜¯å½“æ—¶æ˜¥èŠ‚æ¡£æœŸè¯„åˆ†æœ€é«˜çš„ç”µå½±ã€‚è´¾ç²ä¸ä»…æ˜¯è¯¥ç‰‡çš„å¯¼æ¼”ï¼Œä¹Ÿé€šè¿‡è¯¥ç‰‡è·å¾—äº†è§‚ä¼—å’Œå¸‚åœºçš„å¹¿æ³›è®¤å¯ã€‚\\n\\næ­¤å¤–ï¼Œè´¾ç²è¿˜é€éœ²äº†å¥¹çš„ä¸‹ä¸€éƒ¨ä½œå“çš„ä¸€äº›ä¿¡æ¯ã€‚å¥¹çš„æ–°ç‰‡åä¸ºã€Šè½¬å¿µèŠ±å¼€ã€‹ï¼ˆåˆåã€Šå…‰æ˜ä¹‹æˆ˜ã€‹ï¼‰ï¼Œæ˜¯ä¸€éƒ¨å…³äºåä¼ é”€é¢˜æçš„ç”µå½±ã€‚è¿™éƒ¨ç”µå½±å·²ç»å¤‡æ¡ˆï¼Œå¹¶ä¸”è´¾ç²è¡¨ç¤ºå·²ç»æ‹æ‘„äº†ä¸€éƒ¨åˆ†ï¼Œå‰©ä¸‹çš„ä¸€éƒ¨åˆ†è¿˜åœ¨æ‹æ‘„è®¡åˆ’ä¸­ã€‚è´¾ç²è¿˜æåˆ°ï¼Œå¥¹å·²ç»é‚€è¯·æ¨ç´«å‚ä¸æ–°ç‰‡çš„æ¼”å‡ºï¼Œè¿™å¢åŠ äº†è§‚ä¼—å¯¹è¿™éƒ¨ç”µå½±çš„æœŸå¾…ã€‚')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatZhipuAI()\n",
    "llm.invoke(\"è´¾ç²æœ€æ–°çš„ä½œå“æ˜¯ä»€ä¹ˆï¼Ÿ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='è´¾ç²æ˜¯ä¸­å›½å†…åœ°çš„è‘—åå¥³æ¼”å‘˜ã€å–œå‰§æ¼”å‘˜å’Œåˆ¶ç‰‡äººï¼Œå¥¹æœ‰è®¸å¤šçŸ¥åçš„ä½œå“ã€‚å…¶ä¸­ï¼Œè´¾ç²æœ€è‘—åçš„ä½œå“ä¹‹ä¸€æ˜¯ã€Šæ¬¢ä¹å–œå‰§äººã€‹ã€‚è¿™æ˜¯ä¸€æ¡£å–œå‰§ç«æŠ€ç±»èŠ‚ç›®ï¼Œè´¾ç²ä½œä¸ºå›ºå®šæˆå‘˜å’Œé˜Ÿé•¿ï¼Œå¸¦é¢†å›¢é˜Ÿåœ¨èŠ‚ç›®ä¸­è¡¨æ¼”äº†è®¸å¤šç²¾å½©çš„å–œå‰§ä½œå“ï¼Œæ·±å—è§‚ä¼—å–œçˆ±ã€‚é€šè¿‡è¿™ä¸ªèŠ‚ç›®ï¼Œè´¾ç²å±•ç¤ºäº†è‡ªå·±å‡ºè‰²çš„å–œå‰§è¡¨æ¼”æ‰åï¼Œèµ¢å¾—äº†å¹¿æ³›çš„èµèª‰å’Œäººæ°”ã€‚')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"web_search\",\n",
    "        \"web_search\": {\n",
    "            \"search_query\": \"è´¾ç²æ¼”è¿‡çš„ç›¸å£°\"\n",
    "        }\n",
    "    }\n",
    "]\n",
    "llm = ChatZhipuAI().bind(tools=tools)\n",
    "llm.invoke(\"åˆ—ä¸¾ä¸€ä¸ªè´¾ç²çš„ä½œå“\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='å¾ˆæŠ±æ­‰ï¼Œæ‚¨æ²¡æœ‰æä¾›å…·ä½“çš„èƒŒæ™¯ä¿¡æ¯æˆ–è€…è¯´æ˜ï¼Œæ‰€ä»¥æˆ‘æ— æ³•ç›´æ¥æŒ‡å‡ºè´¾ç²çš„ä½œå“ã€‚è´¾ç²æ˜¯ä¸­å›½çš„ä¸€ä½è‘—åå¥³å–œå‰§æ¼”å‘˜ã€å¯¼æ¼”å’Œåˆ¶ç‰‡äººã€‚å¦‚æœæ‚¨èƒ½æä¾›æ›´å¤šçš„ä¸Šä¸‹æ–‡æˆ–ç»†èŠ‚ï¼Œæ¯”å¦‚å…³äºæŸä¸ªç‰¹å®šèŠ‚ç›®ã€äº‹ä»¶æˆ–è€…ä½œå“çš„ä¿¡æ¯ï¼Œæˆ‘å°†èƒ½å¤Ÿæ›´å¥½åœ°å¸®åŠ©æ‚¨æ‰¾å‡ºè´¾ç²çš„ç›¸å…³ä½œå“ã€‚ä¾‹å¦‚ï¼Œè´¾ç²å› å‚ä¸ã€Šæ¬¢ä¹å–œå‰§äººã€‹ç­‰èŠ‚ç›®ä»¥åŠå¯¼æ¼”å’Œå‚ä¸ç”µå½±ã€Šä½ å¥½ï¼Œæç„•è‹±ã€‹è€Œå¹¿å—æ¬¢è¿ã€‚æä¾›æ›´å¤šç»†èŠ‚åï¼Œæˆ‘å¯ä»¥ä¸ºæ‚¨æä¾›æ›´ç²¾ç¡®çš„ç­”æ¡ˆã€‚')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"web_search\",\n",
    "        \"web_search\": {\n",
    "            \"search_query\": \"è´¾ç²æ¼”è¿‡çš„ç”µå½±\"\n",
    "        }\n",
    "    }\n",
    "]\n",
    "llm = ChatZhipuAI().bind(tools=tools)\n",
    "llm.invoke(\"ä»èƒŒæ™¯ä¿¡æ¯ä¸­æ‰¾å‡ºè´¾ç²çš„ä½œå“\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-chinese-gSQlHcwW-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
