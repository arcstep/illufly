{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "import os\n",
    "os.chdir('..')\n",
    "from langchain_zhipu import ChatZhipuAI, ZhipuAIEmbeddings\n",
    "from langchain_core.messages import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.schema import Document\n",
    "\n",
    "from textlong import (\n",
    "    AskDocumentTool,\n",
    "    create_qa_chain,\n",
    "    create_reason_agent,\n",
    ")\n",
    "from textlong.langgraph import create_tools_calling_executor\n",
    "\n",
    "query_document = Document(page_content=\"langchain_chinese 是为中国大语言模型优化的langchain模块\")\n",
    "\n",
    "db = Chroma.from_documents([query_document], ZhipuAIEmbeddings())\n",
    "\n",
    "llm_zhipu = ChatZhipuAI(model=\"glm-4\")\n",
    "\n",
    "chain = create_qa_chain(llm_zhipu, db.as_retriever())\n",
    "qa_tool = AskDocumentTool(qa_chain=(chain | StrOutputParser()), name=\"qa_chain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              +---------------------------------+          \n",
      "              | Parallel<context,question>Input |          \n",
      "              +---------------------------------+          \n",
      "                    ****               ****                \n",
      "                 ***                       ***             \n",
      "               **                             ***          \n",
      "    +-------------+                              **        \n",
      "    | Lambda(...) |                               *        \n",
      "    +-------------+                               *        \n",
      "            *                                     *        \n",
      "            *                                     *        \n",
      "            *                                     *        \n",
      "+----------------------+                          *        \n",
      "| VectorStoreRetriever |                          *        \n",
      "+----------------------+                          *        \n",
      "            *                                     *        \n",
      "            *                                     *        \n",
      "            *                                     *        \n",
      "+---------------------+                   +-------------+  \n",
      "| Lambda(format_docs) |                   | Lambda(...) |  \n",
      "+---------------------+                   +-------------+  \n",
      "                    ****               ****                \n",
      "                        ***         ***                    \n",
      "                           **     **                       \n",
      "             +----------------------------------+          \n",
      "             | Parallel<context,question>Output |          \n",
      "             +----------------------------------+          \n",
      "                               *                           \n",
      "                               *                           \n",
      "                               *                           \n",
      "                    +--------------------+                 \n",
      "                    | ChatPromptTemplate |                 \n",
      "                    +--------------------+                 \n",
      "                               *                           \n",
      "                               *                           \n",
      "                               *                           \n",
      "                        +-------------+                    \n",
      "                        | ChatZhipuAI |                    \n",
      "                        +-------------+                    \n",
      "                               *                           \n",
      "                               *                           \n",
      "                               *                           \n",
      "                    +-------------------+                  \n",
      "                    | ChatZhipuAIOutput |                  \n",
      "                    +-------------------+                  \n"
     ]
    }
   ],
   "source": [
    "chain.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 2, updating n_results = 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='langchain_chinese 是专门针对中国大语言模型进行优化的langchain模块。它可能是用于提升语言模型在特定应用场景下的表现，比如在中文语境下的理解、生成和推理能力。这个模块的设计目的是为了更好地适应中文语言特点，提高语言模型在中国市场的应用效率和质量。')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke([\"langchain_chinese 是啥\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "import random\n",
    "\n",
    "# @tool(args_schema=WhereIsCatSchema)\n",
    "@tool(\"WhereIsCatHidding\")\n",
    "def where_is_cat_hiding(idea: str) -> str:\n",
    "    \"\"\"从这些地方选择猫躲藏的地方\"\"\"\n",
    "    return random.choice([\"在床底下\", \"在书架中\", \"在阳台\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import ChatOpenAI\n",
    "# llm_zhipu = ChatZhipuAI()\n",
    "tools = [qa_tool, where_is_cat_hiding]\n",
    "app = create_tools_calling_executor(llm_zhipu, tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuehongwei/Library/Caches/pypoetry/virtualenvs/langchain-chinese-gSQlHcwW-py3.9/lib/python3.9/site-packages/langchain_core/_api/beta_decorator.py:86: LangChainBetaWarning: This API is in beta and may change in the future.\n",
      "  warn_beta(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " on_chat_model_start ChatZhipuAI ['seq:step:2']\n",
      "__runnable-name:  qa_chain\n",
      "log: call tool [qa_chain]\n",
      "{}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chunk': [ToolMessage(content='langchain_chinese 是专门针对中国大语言模型进行优化设计的langchain模块。这个模块可能是用于提升语言模型在各种应用场景下的性能和效率，更好地适应中文语言环境的特点。', tool_call_id='call_8483741731860767639')]}\n",
      "{'input': ['请查询资料，告诉我langchain_chinese是什么？', AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_8483741731860767639', 'function': {'arguments': '{\"query\":\"langchain_chinese是什么\"}', 'name': 'qa_chain'}, 'type': 'function'}]})], 'output': [ToolMessage(content='langchain_chinese 是专门针对中国大语言模型进行优化设计的langchain模块。这个模块可能是用于提升语言模型在各种应用场景下的性能和效率，更好地适应中文语言环境的特点。', tool_call_id='call_8483741731860767639')]}\n",
      "\n",
      " on_chat_model_start ChatZhipuAI ['seq:step:2']\n",
      "根据_我的_查询_结果_，_lang_chain__ch_inese_ 是_专门_针对_中国_大_语言_模型_进行_优化_设计的_lang_chain_模块_。_这个_模块_可能是_用于_提升_语言_模型_在各种_应用_场景_下的_性能_和_效率_，_更好地_适应_中文_语言_环境_的特点_。__"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "app = create_tools_calling_executor(\n",
    "    llm_zhipu,\n",
    "    tools = tools,\n",
    "    verbose = True)\n",
    "\n",
    "inputs = [\"请查询资料，告诉我langchain_chinese是什么？\"]\n",
    "async for chunk in app.astream_events(inputs, version=\"v1\"):\n",
    "    # print(\" \"*10, chunk['event'], chunk['name'], chunk['tags'])\n",
    "    if(chunk['event']==\"on_chain_stream\" and chunk['name'] in [\"agent\", \"qa_chain\"]):\n",
    "        print(chunk['data']['chunk'].content, end=\"_\", flush=True)\n",
    "    elif(chunk['name']==\"action\"):\n",
    "        print(chunk['data'])\n",
    "    elif(chunk['event']==\"on_chat_model_start\"):\n",
    "\t    print(\"\\n\", chunk['event'], chunk['name'], chunk['tags'])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    +-----------+             \n",
      "                    | __start__ |             \n",
      "                    +-----------+             \n",
      "                          *                   \n",
      "                          *                   \n",
      "                          *                   \n",
      "                      +-------+               \n",
      "                      | agent |               \n",
      "                     *+-------+*              \n",
      "                   **           ***           \n",
      "                 **                **         \n",
      "               **                    **       \n",
      "+-----------------------+              **     \n",
      "| agent_should_continue |               *     \n",
      "+-----------------------+               *     \n",
      "            *           *****           *     \n",
      "            *                ****       *     \n",
      "            *                    ***    *     \n",
      "       +---------+                +--------+  \n",
      "       | __end__ |                | action |  \n",
      "       +---------+                +--------+  \n"
     ]
    }
   ],
   "source": [
    "app.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " on_chat_model_start ChatZhipuAI ['seq:step:2']\n",
      "__runnable-name:  qa_chain\n",
      "log: call runnable [qa_chain]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " on_chat_model_start ChatZhipuAI ['seq:step:4']\n",
      "lang_chain__ch_inese_ 是_专门_针对_中国_大_语言_模型_进行_优_化的_ lang_chain_ 模_块_。_它_可能是_ lang_chain_ 库_的一个_分支_或_扩展_，_旨在_更好地_适应_中文_语境_和_中国的_相关_技术_需求_。_具体的_细节_需要_查阅_更多_关于_ lang_chain__ch_inese_ 的_官方_文档_或_资料_才能_了解_。__"
     ]
    }
   ],
   "source": [
    "app = create_tools_calling_executor(\n",
    "    llm_zhipu,\n",
    "    tools = tools,\n",
    "    runnables = {\"qa_chain\": chain},\n",
    "    verbose = True)\n",
    "\n",
    "inputs = [\"请查询资料，告诉我langchain_chinese是什么？\"]\n",
    "async for chunk in app.astream_events(inputs, version=\"v1\"):\n",
    "    # print(\" \"*10, chunk['event'], chunk['name'], chunk['tags'])\n",
    "    if(chunk['event']==\"on_chain_stream\" and chunk['name'] in [\"agent\", \"qa_chain\"]):\n",
    "        print(chunk['data']['chunk'].content, end=\"_\", flush=True)\n",
    "    elif(chunk['name']==\"action\"):\n",
    "        print(chunk['data'])\n",
    "    elif(chunk['event']==\"on_chat_model_start\"):\n",
    "\t    print(\"\\n\", chunk['event'], chunk['name'], chunk['tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        +-----------+                     \n",
      "                        | __start__ |                     \n",
      "                        +-----------+                     \n",
      "                              *                           \n",
      "                              *                           \n",
      "                              *                           \n",
      "                          +-------+                       \n",
      "                          | agent |*                      \n",
      "                         *+-------+ ****                  \n",
      "                       **               ***               \n",
      "                     **                    ***            \n",
      "                   **                         ****        \n",
      "    +-----------------------+                     **      \n",
      "    | agent_should_continue |                      *      \n",
      "    +-----------------------+**                    *      \n",
      "           **        **        *******             *      \n",
      "         **            **             *****        *      \n",
      "        *                **                ****    *      \n",
      "+----------+               *                  +--------+  \n",
      "| qa_chain |             **                   | action |  \n",
      "+----------+           **                     +--------+  \n",
      "           **        **                                   \n",
      "             **    **                                     \n",
      "               *  *                                       \n",
      "           +---------+                                    \n",
      "           | __end__ |                                    \n",
      "           +---------+                                    \n"
     ]
    }
   ],
   "source": [
    "app.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              +-----------+                          \n",
      "                              | __start__ |                          \n",
      "                              +-----------+                          \n",
      "                                     *                               \n",
      "                                     *                               \n",
      "                                     *                               \n",
      "                                +-------+                            \n",
      "                               *| agent |***                         \n",
      "                            *** +-------+   ***                      \n",
      "                       *****          *        *****                 \n",
      "                    ***                *            ***              \n",
      "                 ***                   *               *****         \n",
      "+-----------------------+               *                   **       \n",
      "| agent_should_continue |*             *                     *       \n",
      "+-----------------------+ ********     *                     *       \n",
      "               *      *****       *********                  *       \n",
      "               *           ***        *    ********          *       \n",
      "                *             ***    *             *****     *       \n",
      "           +---------+         +--------+              +----------+  \n",
      "           | __end__ |         | action |              | qa_chain |  \n",
      "           +---------+         +--------+              +----------+  \n"
     ]
    }
   ],
   "source": [
    "app = create_tools_calling_executor(\n",
    "    llm_zhipu,\n",
    "    tools = tools,\n",
    "    runnables = {\"qa_chain\": {\"node\": chain, \"to\": \"agent\"}},\n",
    "    verbose = True)\n",
    "app.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " on_chat_model_start ChatZhipuAI ['seq:step:2']\n",
      "__runnable-name:  qa_chain\n",
      "log: call runnable [qa_chain]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " on_chat_model_start ChatZhipuAI ['seq:step:4']\n",
      "lang_chain__ch_inese_ 是_专门_针对_中国_大_语言_模型_进行_优化_和_改进_的_lang_chain_模块_。_它_可能是_lang_chain_这一_框架_的_扩展_或_衍生_版本_，_旨在_更好地_适应_中文_语言_环境_下的_需求_，_提升_大_语言_模型_在_中文_处理_方面的_性能_和_效果_。__\n",
      " on_chat_model_start ChatZhipuAI ['seq:step:2']\n",
      "根据_我的_查询_结果_，_lang_chain__ch_inese_ 是_专门_针对_中国_大_语言_模型_进行_优化_和_改进_的_ lang_chain_ 模_块_。_它是_ lang_chain_ 这一_框架_的_扩展_或_衍生_版本_，_旨在_更好地_适应_中文_语言_环境_下的_需求_，_提升_大_语言_模型_在_中文_处理_方面的_性能_和_效果_。__"
     ]
    }
   ],
   "source": [
    "inputs = [\"请查询资料，告诉我langchain_chinese是什么？\"]\n",
    "async for chunk in app.astream_events(inputs, version=\"v1\"):\n",
    "    # print(\" \"*10, chunk['event'], chunk['name'], chunk['tags'])\n",
    "    if(chunk['event']==\"on_chain_stream\" and chunk['name'] in [\"agent\", \"qa_chain\"]):\n",
    "        print(chunk['data']['chunk'].content, end=\"_\", flush=True)\n",
    "    elif(chunk['name']==\"action\"):\n",
    "        print(chunk['data'])\n",
    "    elif(chunk['event']==\"on_chat_model_start\"):\n",
    "\t    print(\"\\n\", chunk['event'], chunk['name'], chunk['tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__runnable-name:  WhereIsCatHidding\n",
      "log: call tool [WhereIsCatHidding]\n",
      "{}\n",
      "{'chunk': [ToolMessage(content='在床底下', tool_call_id='call_8483752349020160968')]}\n",
      "{'input': [HumanMessage(content='猫在哪里？'), AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_8483752349020160968', 'function': {'arguments': '{\"idea\":\"猫在哪里\"}', 'name': 'WhereIsCatHidding'}, 'type': 'function'}]})], 'output': [ToolMessage(content='在床底下', tool_call_id='call_8483752349020160968')]}\n",
      "根据_我的_观察_和_经验_，_猫_通常会_躲_在一些_狭_小_的地方_，_比如_床_底下_、_沙发_后面_或者_柜_子里_。_所以_，_如果你想_找到_一只_猫_，_最好_在这些_地方_仔细_寻找_。__"
     ]
    }
   ],
   "source": [
    "inputs = [HumanMessage(content=\"猫在哪里？\")]\n",
    "async for chunk in app.astream_events(inputs, version=\"v1\"):\n",
    "    # print(\" \"*10, chunk['event'], chunk['name'], chunk['tags'])\n",
    "    if(chunk['event']==\"on_chain_stream\" and chunk['name'] in [\"agent\", \"qa_chain\"]):\n",
    "        print(chunk['data']['chunk'].content, end=\"_\", flush=True)\n",
    "    elif(chunk['name']==\"action\"):\n",
    "        print(chunk['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__runnable-name:  qa_chain\n",
      "log: call runnable [qa_chain]\n"
     ]
    }
   ],
   "source": [
    "inputs =  [HumanMessage(content=\"霍金的生日是哪一天？\")]\n",
    "async for chunk in app.astream_events(inputs, version=\"v1\"):\n",
    "    # print(\" \"*10, chunk['event'], chunk['name'], chunk['tags'])\n",
    "    if(chunk['event']==\"on_chain_stream\" and chunk['name']==\"agent\"):\n",
    "        print(chunk['data']['chunk'].content, end=\"_\", flush=True)\n",
    "    elif(chunk['name']==\"action\"):\n",
    "        print(chunk['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "为什么_程序员_总是_携带_电脑_？_因为他们_不想_被人_称为_“_裸_奔_者_”。__"
     ]
    }
   ],
   "source": [
    "inputs =  [HumanMessage(content=\"写一个关于程序员的笑话\")]\n",
    "async for chunk in app.astream_events(inputs, version=\"v1\"):\n",
    "    # print(\" \"*10, chunk['event'], chunk['name'], chunk['tags'])\n",
    "    if(chunk['event']==\"on_chain_stream\" and chunk['name']==\"agent\"):\n",
    "        print(chunk['data']['chunk'].content, end=\"_\", flush=True)\n",
    "    elif(chunk['name']==\"action\"):\n",
    "        print(chunk['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchani-book-py3.10-ipykernel",
   "language": "python",
   "name": "langchani-book-py3.10-ipykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
