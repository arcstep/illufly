# textlong 模块规划

## （一）设计目标

**功能定位：**

针对「对话」和「写作」两个核心场景，强化长文写作能力，强化数据分析能力，
并具备基本的流式输出体验、对话记忆能力、知识加载能力、工具回调能力。

同时，直接支持生产环境下所需的模型评测数据提取、安全风险管理、多模型配置管理、并发控制等能力。

**核心概念：**

- 智能体：智能体是对话和写作的上下文环境，包括大模型、提示语模板、推理引擎、知识加载、数据处理工具等
- 记忆：记忆是对话和写作的消息列表历史
- 提示语模板：提示语模板是为了快速构建消息列表，主要支持系统提示语构建
- 推理引擎：推理引擎是指专用于智能体推理的提示语模板，以及解析推理结果的专有模块
- 对话：对话支持多轮对话记忆
- 写作：写作基于提示语模板，会清空对话历史
- 知识：提示语中可插入背景知识，将插入到对话结构中，不受对话长度控制的限制
- 工具：数据分析等工具是内置的，也可以支持自定义的工具
- 历史：历史是工作台的持久化数据，包括对话历史持久化、Markdown持久化、扩写持久化、知识库持久化等
- 工作流：这里的工作流是指智能体的工作流，提供与智能体相同的输入方式，但运行时可以由多个智能体分工协作完成任务
- 数据分析：数据分析是内置的，也是重点支持的工具
- API支持：全框架支持同步、异步、流式输出和SSE
- 支持评测：支持对话过程提取对大模型、提示语、工具、向量库的相关数据，生成评测基础

**功能特性：**

1. 集成生产环境：支持流输出
    - [x] 日志打印：StreamLog流式打印
    - [x] 流式输出：支持模型调用、工具调用、知识检索、扩写调度等全方位流式输出
    - [ ] SSE格式输出：流式输出采用标准化SSE格式，方便前端集成
    - [ ] 异步支持：全框架支持异步，支持自动化异步包装器（例如自定义工具、自定义模型等）
    - [ ] 快速集成：FastAPI集成示范代码

2. 封装大模型：从原生API快速定义大模型
    - [x] 支持大模型自身的工具回调能力
    - [x] 支持openai通用推理模型
    - [x] 通义千问通用推理模型
    - [x] 智谱AI通用推理模型
    - [ ] 步支持多种大模型，如文心一言、讯飞星火、Kimi等
    - [ ] 支持模型混合调用策略
    - [ ] 增加模型Token管理能力
    - [ ] 增加模型费用管理：费率、费用、结算周期
    - [ ] 支持大模型能力评测：提取评测数据

3. 丰富推理模式：封装其他智能体推理，替代大模型计算环节
    - [ ] 内置支持自定义智能体：AgentAction、AgentFinish定义和解析
    - [ ] 内置支持 ReAct
    - [ ] 内置支持 Plan-and-execute
    - [ ] 内置支持 其他智能体

4. 支持多智能体推理：基于智能体、推理引擎和代码逻辑定义
    - [ ] 支持顺序执行
    - [ ] 支持循环执行
    - [ ] 支持并行执行

5. 支持智能体工作台数据持久化：可从历史状态恢复
    - [ ] 支持工作台持久化：将记忆、数据、知识、写作成果等保存到本地文件，并支持恢复
    - [ ] 支持其他持久化策略：sqlite、redis、mysql、mongodb等

6. 支持对话模式：支持多轮对话
    - [x] 支持多轮对话
    - [x] 支持基于写作成果做多轮对话，仅评论、不重写
    - [ ] 支持基于写作成果做多轮对话，实现重写（显示调用保存到写作成果）
    - [ ] 支持基于局部扩写成果做多轮对话，仅评论、不重写
    - [ ] 支持基于局部扩写成果做多轮对话，实现重写（显示调用保存到写作成果）
    - [ ] 支持对话历史保存和加载（在工作台持久化中实现）
    - [ ] 可进一步通过对话生成知识

7. 支持写作模式：
    - [x] 支持创意模板
    - [x] 支持提纲模板
    - [x] 支持扩写模板
    - [ ] 生成带有图片、表格、图表、流程图的文稿提纲
    - [ ] 针对图片、表格、图表、流程图扩写
    - [ ] 支持版本管理，回复历史写作成果、扩写成果
    - [ ] 支持扩写的局部重写任务
    - [ ] 支持提纲的局部重写任务

8. 封装提示语结构：支持对话提示语模板
    - [x] 支持在提示语中优化嵌入知识背景
    - [x] 支持在提示语中嵌入对话历史
    - [ ] 支持提示语模板的版本管理
    - [ ] 支持提示语模板的本地模板

9. 支持数据分析：使用工具回调智能体
    - [ ] 工作台支持数据加载器：excel、csv、parquet
    - [ ] 工作台支持数据连接器： mysql、postgresql、sqlite、duckdb
    - [x] 工具支持 pandas 代码生成和执行
    - [ ] 工具支持 polar 代码生成和执行
    - [ ] 工具支持 mysql 代码生成和执行
    - [ ] 工具支持 duckdb 代码生成和执行

10. 封装更多回调工具：全面集成多模态能力
    - [ ] 支持探索式数据分析，支持在工具中生成工作台内容（如数据集）
    - [ ] 支持网络搜索
    - [ ] 支持文生图模型
    - [ ] 支持文生视频模型
    - [ ] 支持图片理解模型
    - [ ] 支持视频理解模型

11. 封装知识加载：从工作台加载知识知识
    - [x] 支持加载知识到工作台，并去重
    - [x] 支持在多轮对话、写作等模式中嵌入知识，回避对话长度限制，且避免重复嵌入
    - [ ] 支持通过文件加载背景知识
    - [ ] 支持通过向量检索加载背景知识
    - [ ] 支持动态获取知识：支持溯源
    - [ ] 支持临时选择工作台已有知识

12. 支持向量检索：
    - [ ] 通用方法：导入、编码、存储、检索、溯源
    - [ ] 支持多种向量模型：openai、通义千问、智谱AI等
    - [ ] 支持多种向量库：chroma、Faiss、milvus、lanceDB等
    - [ ] 支持文本嵌入缓冲：本地缓冲
    - [ ] 支持更多缓冲存储方案：redis缓冲、mysql缓冲、mongodb缓冲等

13. 导入文档：将文档转化为知识或向量库
    - [ ] 纯文本文档导入
    - [ ] markdown 文档导入
    - [ ] pdf 文档导入
    - [ ] 图片导入
    - [ ] 视频导入
    - [ ] 音频导入
    - [ ] html 文档导入
    - [ ] 网页链接导入
    - [ ] 网站爬取导入

14. 导出文档：分享对话内容和成果
    - [ ] 将工作台内容导出为 markdown 文档
    - [ ] 将多轮对话内容发布为共享网页
    - [ ] 将工作台内容发布为共享网页
    - [ ] 将工作台内容发布为摘要和对话主题

15. 支持生成评测数据
    - [ ] 从对话历史中提取模型评测数据
    - [ ] 从对话历史中提取工具评测数据
    - [ ] 从对话历史中提取知识召回评测数据
    - [ ] 从对话历史中提取提示语模板评测数据
    - [ ] 从对话历史中提取提纲生成评测数据
    - [ ] 从对话历史中提取扩写生成评测数据

16. 支持安全风险防范管理
    - [ ] 自动审查知识库管理
    - [ ] 支持用户提问审查和据答机制：自动审查和抽查
    - [ ] 支持知识管理审查和禁用机制：自动审查和抽查
    - [ ] 支持工具管理审查和禁用机制：自动审查和抽查
    - [ ] 支持对生成结果审查和溯源机制：自动审查和抽查
    - [ ] 支持对严重违禁用户停服机制：黑名单管理

## （二）结构设计

在工作台智能体的设计要点中：
- 输入到输出的主流程是函数式调用（即幂等调用，调用多次无修改变量的副作用）
- 在长期记忆中保存多轮的文本对话历史
- 在工作台中保存等结构化数据、大文本文稿、流程图等需要在多轮对话中持续聚焦的状态
- 每个项目实例有一个工作台

```mermaid
graph LR
    INPUT((输入))
    Prompt(提示语模板)
    LLM(大模型)
    OUTPUT((输出))
    DB[[向量库]]
    Knowledge[知识]
    Tools(工具\n BI/工单)
    Workshop(工作台\n 数据/讲稿)
    Pen[指令]
    LongtermMemory(长期记忆)
    Topic[[持久会话]]
    Project[[项目上下文环境]]

    style INPUT fill:#f9f,stroke:#333,stroke-width:4px
    style OUTPUT fill:#f9f,stroke:#333,stroke-width:4px
    style Prompt fill:#ccf,stroke:#333,stroke-width:4px
    style LLM fill:#ccf,stroke:#333,stroke-width:4px
    
    INPUT -->|指定| Topic
    INPUT ==>|填充| Prompt -->|观察| Workshop
    INPUT -->|检索| DB -->|召回| Knowledge -->|填充| Prompt
    Prompt ==>|调用| LLM -->|选择| Tools -->|反馈| LLM
                                 Tools -->|修改| Workshop

    LLM ==>|生成| OUTPUT -->|提取| Pen -->|呈现| Workshop
                 OUTPUT -->|保存到| Topic

    Topic -->|属于| Project -->|管理| Workshop
    Topic -->|提取| LongtermMemory -->|填充| Prompt

```

## （三）工具构造

- 数据分析工具的入参和结果
- 信号控制工具的入参和结果
- 大屏操作指令的入参和结果
- 工单跟踪工具的入参和结果

## （四）效果评测和反向构造

- 【提示语对齐】评测大模型的提示语对齐能力
    - 反向构造：根据知识片段（或相关概念），构造问题
    - 反向构造：根据工具调用结果，构造问题
- 【知识召回】根据较好的提示语模板，评测各个RAG方案的知识召回能力
    - 反向构造：根据工具调用结果和知识片段（或相关概念），构造问题
- 【工具命中】根据较好的提示语模板，评测各个大模型的工具命中能力
    - 反向构造：根据工具调用入参，构造问题
- 【工具命中】根据选中的提示语模板和大模型，结合RAG评价工具命中能力
    - 反向构造：根据工具调用入参和知识片段（或相关概念），构造问题
- 【新概念发现】根据选中的提示语模板和大模型，结合RAG评价新概念发现能力
    - 反向构造：根据工具调用入参和知识片段（或相关概念），构造问题
    - 反向构造：根据新概念和知识片段（或相关概念），构造问题

# 二、对话工作台结构

## 1、工作台结构

```mermaid
graph LR
    INPUT[输入]
    Prompt[提示语]
    DB[知识向量库]
    OUTPUT[输出内容]
    LLM[大语言模型]
    Tools[回调工具]
    Slide[工作台内容\n 数据/图表/文稿]
    Cursor[演示指令]
    Memory[短期记忆]

    INPUT -->|检索| DB -->|召回| INPUT -->|构造| Prompt
    Prompt -->|调用| LLM -->|选择| Tools -->|反馈| LLM
    Tools -->|修改| Slide
    LLM -->|生成| OUTPUT -->|修改| Slide
    LLM -->|生成| Memory -->|被..引用| Prompt
    OUTPUT -->|嵌入| Cursor -->|呈现| Slide
    Slide -->|被..引用| INPUT
```

### 场景1 流程展示
- 工作台内容即流程图定义的`mermaid`文本
- 演示指令就是流程图呈现，以及当前解说步骤的工作流节点
- 大模型输出时，同步输出数据、流程节点指示和流程说明的文本解说

### 场景2 数据分析
- 工作台内容即数据选择和`pandas`数据加载
- 演示指令就是数据呈现的图表，以及高亮、选择等操作
- 大模型输出时，同步输出数据、图表、演示操作和解说文本

## 2、知识召回优化

这主要适合如下场景：

- 知识库整体规模不大，但要求非常高的匹配度
- 适合结合人类参与、头脑风暴的方式构建问题库的初始问题清单
- 通过扩散模型扩散问题清单后，所形成的问题规模不大，可以通过向量数据库存储和检索

在初期使用时，可以使用通用模型结合`textlong`的响应提示语模板替代。

### 检索示例

在AI应用，使用`RAG`做检索时使用【扩散问题+答案】检索，并按照【答案】对结果去重。

```mermaid
graph BT
    Q11[扩散问题]
    Q12[扩散问题]
    Q13[...]
    Q21[扩散问题]
    Q22[扩散问题]
    Q23[...]
    Q1[问题1]
    Q2[问题2]
    A1[答案1]
    A2[答案2]
    V[[知识向量库]]

    Q11 --> Q1
    Q12 --> Q1
    Q13 --> Q1

    Q21 --> Q2
    Q22 --> Q2
    Q23 --> Q2

    Q1 -->|绑定| A1 --> V
    Q2 -->|绑定| A2 --> V
```


- **构建**知识文档时，考虑【问题驱动】的方式构建知识结构。
- **存储**知识文档时，使用【扩散问答】的方法，扩大问题覆盖面，提高召回率。
- **检索**知识文档时，连同【问题+答案】一起检索，并按照【答案】合并相同结果。

## 3、提示语模板选择

## 4、回调工具

## 5、短期记忆优化

考虑写作场景，默认支持记忆过程中的【问答压缩】，避免单轮回答时生成长文过长占用历史。
具体压缩技巧包括：

- 针对提问的问题，保留前50个字和最后50个字，使其总数量不超过100个字
- 针对AI生成的回答，过滤掉 yaml 开头的部份，保留前50个字和最后50个字

## 6、嵌入演示指令

# 三、写作任务

## 1、结合提示语中的知识背景，编写扩写指南
若构建的知识库中包含代码示例、图表、表格等，应当追加其引用说明，并在生成提纲时提前从知识库中获得这些资料的背景知识。

- **图表：** 可使用`mermaid`语法绘制流程图、用例图、时序图、状态图、甘特图等。
- **表格：** 可使用`markdown`语法绘制表格。

>
- 在扩写指南中增加代码示例的描述
- 在扩写指南中增加图表的描述
- 在扩写指南中增加表格的描述

## 2、结合提示语中的知识背景，完成扩写

- 在扩写包含代码示例的段落时，应当优先考虑已有的代码示范
- 在扩写包含图表的段落时，应当优先参考已有的图表
- 在扩写包含表格数据的段落时，应当优先参考已有的表格


# 四、模型微调需求

## 1、数据分析大模型
按照数据分析习惯，生成数据分析的回调工具。
最好结合垂直行业情况来微调模型。

在初期使用时，可以使用通用模型结合`textlong`的响应提示语模板替代。

## 2、问答知识生成大模型
按照文档内容，以问题驱动的策略生成知识结构。
最好结合垂直行业情况，精心设计问题清单，以问题驱动的策略生成。

在初期使用时，可以使用通用模型结合`textlong`的响应提示语模板替代。

## 3、问答知识扩散大模型
从问题驱动的知识库中，将问题扩散数十倍、数百倍的问题数量。
这相当于构建【QA对】的缓冲机制。

这些问题必须适合使用文本向量比较的方法从问题中比对，以便通过RAG的方式完成知识召回。在具体的扩散策略中，应当结合垂直行业情况、数据分析等特点进行微调，以便按照特定的目标领域进行问题扩散。

## 4、内容演示大模型
按照内容特点和演示目的，生成演示讲解指令。

在初期使用时，可以使用通用模型结合`textlong`的响应提示语模板替代。
